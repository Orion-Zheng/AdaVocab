{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        },
        {
            "name": "Debug AdaVocab",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            "cwd": "${workspaceFolder}",
            "args": [
                "--config_file",
                "config/accelerate_config/nscc/one_node_one_gpu.yaml",
                "--gradient_accumulation_steps", "1",
                "--gradient_clipping", "1.0",
                "--mixed_precision", "bf16",
                "train.py",
                "--run_name", "AdaVocab",
                "--model_dir", "original_models/tinyllama-chat",
                "--tokenizer_dir", "original_models/tinyllama-chat",
                "--train_data_dir", "tokenized_datasets/wildchat_tinyllama-chat_2048_ft",
                "--eval_data_dir", "tokenized_datasets/wildchat_tinyllama-chat_1M_eval_fake",
                "--output_dir", "experiment_ckpts/AdaVocab_debug",
                "--gradient_accumulation_steps", "1",
                "--per_device_eval_batch_size", "1",
                "--per_device_train_batch_size", "1",
                "--max_token_per_seq", "2048",
                "--eval_steps", "10",
                "--save_steps", "10",  
                "--learning_rate", "2e-5",
                "--optim", "paged_adamw_32bit",
                "--adam_beta1", "0.9",
                "--adam_beta2", "0.95",
                "--weight_decay", "0.01",
                "--lr_scheduler_type", "cosine",
                "--num_train_epochs", "1",
                // "--max_steps", "3", 
                "--warmup_ratio", "0.03",
                "--seed", "42",
                "--load_dtype", "bfloat16",
                "--dataloader_num_workers", "0",
                "--gradient_checkpointing", "True",
                "--max_grad_norm", "1.0",
                "--use_flash", "True",
                "--do_train", "True",
                "--bf16", "True",
                "--freeze_non_embed", "False"
            ],
            "console": "integratedTerminal",
            "justMyCode": false
        }
    ]
}